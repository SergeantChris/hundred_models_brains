---
layout: default
---

What can we learn from comparing video models to human brains, arguably the
most efficient and effective video processing systems in existence? Our work
takes a step towards answering this question by performing the first large-scale
benchmarking of deep video models on representational alignment to the human
brain, using publicly available models and a recently released video brain imaging
(fMRI) dataset.

![RSA](./RSA.png)

# Temporal

![ImagevsVideo](./IvsV.png)

![Rank](./rank.png)

# Arch

![CNNvsTransformer](./CvsT.png)

# Dataset

![KineticsvsSthsth](./KvsS.png)

# Computational complexity

![Flops](./flops.png)

# BibTeX
```
@inproceedings{
  sartzetaki2025one,
  title={One Hundred Neural Networks and Brains Watching Videos: Lessons from Alignment},
  author={Christina Sartzetaki and Gemma Roig and Cees G. M. Snoek and Iris Groen},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=LM4PYXBId5}
}
```
