- name: 'ircsn_bnfrozen_r152_ig65m'
  type: 'video-k400'
  params: 29.7
  flops: 97.63
  accuracy: 82.84
  time_as: "input_dim_local"
  pre: 'prevideo'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ircsn_ig65m-pretrained-r152-bnfrozen_8xb12-32x2x1-58e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/ircsn_ig65m-pretrained-r152-bnfrozen_8xb12-32x2x1-58e_kinetics400-rgb_20220811-7d1dacde.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'ircsn_bnfrozen_r50_ig65m'
  type: 'video-k400'
  params: 13.13
  flops: 55.90
  accuracy: 79.44
  time_as: "input_dim_local"
  pre: 'prevideo'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ircsn_ig65m-pretrained-r50-bnfrozen_8xb12-32x2x1-58e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/ircsn_ig65m-pretrained-r50-bnfrozen_8xb12-32x2x1-58e_kinetics400-rgb_20220811-44395bae.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'ircsn_r152_ig65m'
  type: 'video-k400'
  params: 29.7
  flops: 97.63
  accuracy: 82.87
  time_as: "input_dim_local"
  pre: 'prevideo'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ircsn_ig65m-pretrained-r152_8xb12-32x2x1-58e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/ircsn_ig65m-pretrained-r152_8xb12-32x2x1-58e_kinetics400-rgb_20220811-c7a3cc5b.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'ircsn_r152'
  type: 'video-k400'
  params: 29.7
  flops: 97.6
  accuracy: 76.53
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ircsn_r152_32x2x1-180e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/vmz_ircsn_from_scratch_r152_32x2x1_180e_kinetics400_rgb_20210617-5c933ae1.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'ipcsn_bnfrozen_r152_ig65m'
  type: 'video-k400'
  params: 33.02
  flops: 109.9
  accuracy: 82.68
  time_as: "input_dim_local"
  pre: 'prevideo'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ipcsn_ig65m-pretrained-r152-bnfrozen_32x2x1-58e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/vmz_ipcsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20210617-c3be9793.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'ipcsn_r152'
  type: 'video-k400'
  params: 33.02
  flops: 109.9
  accuracy: 77.80
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/csn/ipcsn_r152_32x2x1-180e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/csn/vmz_ipcsn_from_scratch_r152_32x2x1_180e_kinetics400_rgb_20210617-d565828d.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'i3d_r50_mma'
  type: 'video-k400'
  params: 28.0
  flops: 43.5
  accuracy: 73.47
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/i3d/i3d_imagenet-pretrained-r50_8xb8-32x2x1-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/i3d/i3d_imagenet-pretrained-r50_8xb8-32x2x1-100e_kinetics400-rgb_20220812-e213c223.pth
  layers: [ 'backbone.conv1', 'backbone.layer1', 'backbone.layer2', 'backbone.layer3', 'backbone.layer4', 'cls_head' ]
  rsa_skips: ['cls_head']

- name: 'i3d_r50_dotprod'
  type: 'video-k400'
  params: 35.4
  flops: 59.3
  accuracy: 74.80
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/i3d/i3d_imagenet-pretrained-r50-nl-dot-product_8xb8-32x2x1-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/i3d/i3d_imagenet-pretrained-r50-nl-dot-product_8xb8-32x2x1-100e_kinetics400-rgb_20220812-8e1f2148.pth
  rsa_skips: ['backbone_maxpool', 'backbone_pool2', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'i3d_r50_embgauss'
  type: 'video-k400'
  params: 35.4
  flops: 59.3
  accuracy: 74.73
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/i3d/i3d_imagenet-pretrained-r50-nl-embedded-gaussian_8xb8-32x2x1-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/i3d/i3d_imagenet-pretrained-r50-nl-embedded-gaussian_8xb8-32x2x1-100e_kinetics400-rgb_20220812-afd8f562.pth
  rsa_skips: ['backbone_maxpool', 'backbone_pool2', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'i3d_r50_gauss'
  type: 'video-k400'
  params: 31.7
  flops: 56.5
  accuracy: 73.97
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/i3d/i3d_imagenet-pretrained-r50-nl-gaussian_8xb8-32x2x1-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/i3d/i3d_imagenet-pretrained-r50-nl-gaussian_8xb8-32x2x1-100e_kinetics400-rgb_20220812-0c5cbf5a.pth
  rsa_skips: ['backbone_maxpool', 'backbone_pool2', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'i3d_r50_heavy'
  type: 'video-k400'
  params: 33.0
  flops: 166.3
  accuracy: 76.21
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/i3d/i3d_imagenet-pretrained-r50-heavy_8xb8-32x2x1-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/i3d/i3d_imagenet-pretrained-r50-heavy_8xb8-32x2x1-100e_kinetics400-rgb_20220812-ed501b31.pth
  rsa_skips: ['backbone_maxpool', 'backbone_pool2', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'r2plus1d_r50_mma'
  type: 'video-k400'
  params: 63.8
  flops: 213
  accuracy: 75.46
  time_as: "input_dim_factorized"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/r2plus1d/r2plus1d_r34_8xb8-32x2x1-180e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/r2plus1d/r2plus1d_r34_8xb8-32x2x1-180e_kinetics400-rgb_20220812-4270588c.pth
  layers: [ 'backbone.conv1', 'backbone.layer1', 'backbone.layer2', 'backbone.layer3', 'backbone.layer4', 'cls_head' ]
  rsa_skips: ['cls_head']

- name: 'slowfast_r50_mma'
  type: 'video-k400'
  params: 34.6
  flops: 66.1
  accuracy: 76.8
  time_as: "input_dim_multires"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowfast/slowfast_r50_8xb8-8x8x1-256e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slowfast/slowfast_r50_8xb8-8x8x1-256e_kinetics400-rgb_20220818-1cb6dfc8.pth
  layers: [ 'backbone.slow_path.conv1', 'backbone.slow_path.layer1', 'backbone.slow_path.layer2', 'backbone.slow_path.layer3', 'backbone.slow_path.layer4', 'backbone.slow_path.conv1_lateral', 'backbone.slow_path.layer1_lateral', 'backbone.slow_path.layer2_lateral', 'backbone.slow_path.layer3_lateral', 'backbone.fast_path.conv1', 'backbone.fast_path.layer1', 'backbone.fast_path.layer2', 'backbone.fast_path.layer3', 'backbone.fast_path.layer4', 'cls_head' ]
  rsa_skips: ['cls_head']

- name: 'slowfast_r101_mma'
  type: 'video-k400'
  params: 62.9
  flops: 126
  accuracy: 78.65
  time_as: "input_dim_multires"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 32
    frame_interval: 2
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowfast/slowfast_r101_8xb8-8x8x1-256e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slowfast/slowfast_r101_8xb8-8x8x1-256e_kinetics400-rgb_20220818-9c0e09bd.pth
  layers: [ 'backbone.slow_path.conv1', 'backbone.slow_path.layer1', 'backbone.slow_path.layer2', 'backbone.slow_path.layer3', 'backbone.slow_path.layer4', 'backbone.slow_path.conv1_lateral', 'backbone.slow_path.layer1_lateral', 'backbone.slow_path.layer2_lateral', 'backbone.slow_path.layer3_lateral', 'backbone.fast_path.conv1', 'backbone.fast_path.layer1', 'backbone.fast_path.layer2', 'backbone.fast_path.layer3', 'backbone.fast_path.layer4', 'cls_head' ]
  rsa_skips: [ 'cls_head' ]

- name: 'slow_r50_mma'
  type: 'video-k400'
  params: 32.45
  flops: 54.75
  accuracy: 75.15
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 8
    frame_interval: 8
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowonly/slowonly_r50_8xb16-8x8x1-256e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slow/slowonly_r50_8xb16-8x8x1-256e_kinetics400-rgb_20220901-2132fc87.pth
  layers: [ 'backbone.conv1', 'backbone.layer1', 'backbone.layer2', 'backbone.layer3', 'backbone.layer4', 'cls_head' ]
  rsa_skips: ['cls_head']

- name: 'slow_r101'
  type: 'video-k400'
  params: 60.36
  flops: 112
  accuracy: 76.59
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 8
    frame_interval: 8
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowonly/slowonly_r101_8xb16-8x8x1-196e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slow/slowonly_r101_8xb16-8x8x1-196e_kinetics400-rgb_20220901-e6281431.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'slow_r50_in1k'
  type: 'video-k400'
  params: 32.45
  flops: 54.75
  accuracy: 76.45
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 8
    frame_interval: 8
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowonly/slowonly_imagenet-pretrained-r50_8xb16-8x8x1-steplr-150e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slow/slowonly_imagenet-pretrained-r50_8xb16-8x8x1-steplr-150e_kinetics400-rgb_20220901-df42dc84.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'slow_r50_in1k_embgauss'
  type: 'video-k400'
  params: 39.81
  flops: 96.66
  accuracy: 76.65
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 8
    frame_interval: 8
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/slowonly/slowonly_r50-in1k-pre-nl-embedded-gaussian_8xb16-8x8x1-steplr-150e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/slow/slowonly_r50-in1k-pre-nl-embedded-gaussian_8xb16-8x8x1-steplr-150e_kinetics400-rgb_20220901-df42dc84.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tanet_r50'
  type: 'video-k400'
  params: 25.6
  flops: 43
  accuracy: 76.22
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
    dense_sampling: True
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tanet/tanet_imagenet-pretrained-r50_8xb8-dense-1x1x8-100e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tanet/tanet_imagenet-pretrained-r50_8xb8-dense-1x1x8-100e_kinetics400-rgb_20220919-a34346bc.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tpn_r50'
  type: 'video-k400'
  params: 32
  flops: 54
  accuracy: 74.20
  time_as: "input_dim_multires"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 8
    frame_interval: 8
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tpn/tpn-slowonly_r50_8xb8-8x8x1-150e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tpn/tpn-slowonly_r50_8xb8-8x8x1-150e_kinetics400-rgb_20220913-97d0835d.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool3d', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tsm_r50'
  type: 'video-k400'
  params: 23.87
  flops: 32.88
  accuracy: 73.18
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 224
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tsm/tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tsm/tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20220831-64d69186.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tsm_r50_dotprod'
  type: 'video-k400'
  params: 31.68
  flops: 61.3
  accuracy: 74.49
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 224
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tsm/tsm_imagenet-pretrained-r50-nl-dot-product_8xb16-1x1x8-50e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tsm/tsm_imagenet-pretrained-r50-nl-dot-product_8xb16-1x1x8-50e_kinetics400-rgb_20220831-108bfde5.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tsm_r50_gauss'
  type: 'video-k400'
  params: 28
  flops: 59.06
  accuracy: 73.66
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 224
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tsm/tsm_imagenet-pretrained-r50-nl-gaussian_8xb16-1x1x8-50e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tsm/tsm_imagenet-pretrained-r50-nl-gaussian_8xb16-1x1x8-50e_kinetics400-rgb_20220831-7e54dacf.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tsm_r50_embgauss'
  type: 'video-k400'
  params: 31.68
  flops: 61.3
  accuracy: 74.34
  time_as: "input_dim_localglobal"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 224
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tsm/tsm_imagenet-pretrained-r50-nl-embedded-gaussian_8xb16-1x1x8-50e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tsm/tsm_imagenet-pretrained-r50-nl-embedded-gaussian_8xb16-1x1x8-50e_kinetics400-rgb_20220831-35eddb57.pth
  rsa_skips: ['backbone_maxpool', 'cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'tsm_r50_mobones4_16'
  type: 'video-k400'
  params: 13.72
  flops: 48.65
  accuracy: 74.38
  time_as: "input_dim_local"
  pre: 'preimage'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 1
    frame_interval: 1
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
    format_shape: 'NCHW'
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/tsm/tsm_imagenet-pretrained-mobileone-s4_8xb16-1x1x16-50e_kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/tsm/tsm_imagenet-pretrained-mobileone-s4_8xb16-1x1x16-50e_kinetics400-rgb_20230825-a7f8876b.pth
  rsa_skips: ['cls_head_avg_pool', 'cls_head_consensus', 'cls_head_dropout', 'cls_head_fc_cls']

- name: 'x3d_s'
  type: 'video-k400'
  params: 3.76
  flops: 1.96
  accuracy: 73.2
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 13
    frame_interval: 6
    resize_size: 182
    crop_type: 'center_crop'
    crop_size: 182
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/x3d/x3d_s_13x6x1_facebook-kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/x3d/x3d_s_13x6x1_facebook-kinetics400-rgb_20201027-623825a0.pth
  rsa_skips: ['backbone_conv1_t_activate', 'backbone_conv1_t_bn', 'cls_head_dropout', 'cls_head_pool',
              'cls_head_relu', 'cls_head_fc1', 'cls_head_fc2']

- name: 'x3d_m'
  type: 'video-k400'
  params: 3.76
  flops: 4.73
  accuracy: 75.2
  time_as: "input_dim_local"
  pre: 'nopre'
  set: # leave None
  netset_fallback: 'Pyvideo'
  extractor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.extract_mmaction
    stage: 'head'  # 'backbone', 'neck', or 'head'
  preprocessor:
    _partial_: True
    _target_: repralign.models.custom_extraction_functions.preprocess_mmaction
    clip_len: 16
    frame_interval: 5
    resize_size: 256
    crop_type: 'center_crop'
    crop_size: 256
  cfg:
    _target_: repralign.models.loading.mmaction_loader
    path_to_config: ${location}/workspace/code/mmaction2/configs/recognition/x3d/x3d_m_16x5x1_facebook-kinetics400-rgb.py
    path_to_checkpoint: ${location}/workspace/code/mmaction2/checkpoints/x3d/x3d_m_16x5x1_facebook-kinetics400-rgb_20201027-3f42382a.pth
  rsa_skips: ['backbone_conv1_t_activate', 'backbone_conv1_t_bn', 'cls_head_dropout', 'cls_head_pool',
              'cls_head_relu', 'cls_head_fc1', 'cls_head_fc2']